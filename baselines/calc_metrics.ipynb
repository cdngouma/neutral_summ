{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e897862-ee66-444d-ba12-1a2574cf9d26",
   "metadata": {},
   "source": [
    "The purpose of this Notebook is to compute the ROUGE scores using the reference summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ba32af2-26cc-4b22-8595-8ef499c0ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0178eef0-f0b1-4487-8d4a-3d08bb052096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8ca912-c8af-4038-ad2d-2e9e8c929d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332f2226-5e3b-4c5a-b690-1ab366daa425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "769d36a6-4027-4dad-a08d-5badd4892a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    #INVALID_POS = [\"CC\", \"CD\", \"DT\", \"EX\", \"IN\", \"LS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RP\", \"TO\", \"WDT\", \"WP\", \"WRB\"]\n",
    "    INVALID_POS = [\"CC\", \"CD\", \"DT\", \"EX\", \"IN\", \"LS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RP\", \"TO\", \"WDT\", \"WP\", \"WRB\"]\n",
    "    sentence = re.sub(f\"[{re.escape(string.punctuation)}\\…]+\", \" \", sentence)\n",
    "    # Filter common words\n",
    "    tokens = nltk.pos_tag(sentence.split())\n",
    "    tokens_ = tokens\n",
    "    tokens = [tok for (tok, pos) in tokens if tok.lower() not in stop_words and pos not in INVALID_POS]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a1bf2b-7a9d-4a62-8e10-f9dd192fb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11752a27-92a3-48bd-a721-8eb09dd25988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs = pd.read_csv(\"./reference_summaries.csv\")\n",
    "refs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cb1845-5c6e-49f5-8ed1-9a122b9d6408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_id</th>\n",
       "      <th>summ_1</th>\n",
       "      <th>summ_2</th>\n",
       "      <th>summ_3</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JCDUFG</td>\n",
       "      <td>the customers feel that the newspaper they bou...</td>\n",
       "      <td>the newspaper is a nice read with updated news...</td>\n",
       "      <td>the newspaper is easy to read and navigate and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000M92GLK</td>\n",
       "      <td>a headset that is light and comfortable with a...</td>\n",
       "      <td>this bluetooth handsfree works great, has very...</td>\n",
       "      <td>the headset is well made and it's really easy ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000Q5J2M6</td>\n",
       "      <td>Overall the reviews are mixed, while some user...</td>\n",
       "      <td>A lightweight Bluetooth headset. Compatible wi...</td>\n",
       "      <td>the headset offers good volume control for inc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000SRGF2W</td>\n",
       "      <td>This short military romance story, Male Call, ...</td>\n",
       "      <td>short story with a lot of sex. seems a bit imm...</td>\n",
       "      <td>the book brings fun to readers, at a good pric...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000WCWUWM</td>\n",
       "      <td>a simple and fast paced book with interesting ...</td>\n",
       "      <td>the book is decent, with a simple storyline an...</td>\n",
       "      <td>a basic and simple love story to read. charact...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>B00CX1LJJK</td>\n",
       "      <td>This phone case is cute and is of decent quali...</td>\n",
       "      <td>May be a poor fit for your phone. Ears come of...</td>\n",
       "      <td>the ears can come off easily at times and the ...</td>\n",
       "      <td>2 disagreements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>B00CYNN4ZO</td>\n",
       "      <td>The phone case make it hard to charge the phon...</td>\n",
       "      <td>this plastic case is water resistant and it pr...</td>\n",
       "      <td>This case is great if it is used extreme condi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>B00IY5RM04</td>\n",
       "      <td>This short book is about a fun erotic story. A...</td>\n",
       "      <td>this is an adult book as a warning. it is a qu...</td>\n",
       "      <td>this book is good to read abut not enough sex ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>B00K7Q8I1A</td>\n",
       "      <td>a short book about love. it ends at a cliffhan...</td>\n",
       "      <td>the book was nice to read but one have buy nex...</td>\n",
       "      <td>This erotic book is good overall. However, the...</td>\n",
       "      <td>2 disagreements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>B00LADYBSS</td>\n",
       "      <td>This thriller deals with the American legal an...</td>\n",
       "      <td>a novel depicting a criminal justice / courtro...</td>\n",
       "      <td>Two criminals stand trial for a crime in this ...</td>\n",
       "      <td>2 disagreements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prod_id                                             summ_1  \\\n",
       "0    B000JCDUFG  the customers feel that the newspaper they bou...   \n",
       "1    B000M92GLK  a headset that is light and comfortable with a...   \n",
       "2    B000Q5J2M6  Overall the reviews are mixed, while some user...   \n",
       "3    B000SRGF2W  This short military romance story, Male Call, ...   \n",
       "4    B000WCWUWM  a simple and fast paced book with interesting ...   \n",
       "..          ...                                                ...   \n",
       "195  B00CX1LJJK  This phone case is cute and is of decent quali...   \n",
       "196  B00CYNN4ZO  The phone case make it hard to charge the phon...   \n",
       "197  B00IY5RM04  This short book is about a fun erotic story. A...   \n",
       "198  B00K7Q8I1A  a short book about love. it ends at a cliffhan...   \n",
       "199  B00LADYBSS  This thriller deals with the American legal an...   \n",
       "\n",
       "                                                summ_2  \\\n",
       "0    the newspaper is a nice read with updated news...   \n",
       "1    this bluetooth handsfree works great, has very...   \n",
       "2    A lightweight Bluetooth headset. Compatible wi...   \n",
       "3    short story with a lot of sex. seems a bit imm...   \n",
       "4    the book is decent, with a simple storyline an...   \n",
       "..                                                 ...   \n",
       "195  May be a poor fit for your phone. Ears come of...   \n",
       "196  this plastic case is water resistant and it pr...   \n",
       "197  this is an adult book as a warning. it is a qu...   \n",
       "198  the book was nice to read but one have buy nex...   \n",
       "199  a novel depicting a criminal justice / courtro...   \n",
       "\n",
       "                                                summ_3         comments  \n",
       "0    the newspaper is easy to read and navigate and...              NaN  \n",
       "1    the headset is well made and it's really easy ...              NaN  \n",
       "2    the headset offers good volume control for inc...              NaN  \n",
       "3    the book brings fun to readers, at a good pric...              NaN  \n",
       "4    a basic and simple love story to read. charact...              NaN  \n",
       "..                                                 ...              ...  \n",
       "195  the ears can come off easily at times and the ...  2 disagreements  \n",
       "196  This case is great if it is used extreme condi...              NaN  \n",
       "197  this book is good to read abut not enough sex ...              NaN  \n",
       "198  This erotic book is good overall. However, the...  2 disagreements  \n",
       "199  Two criminals stand trial for a crime in this ...  2 disagreements  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935f3de0-2be7-4f6a-a57d-03293e5c8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(path, refs):\n",
    "    df = pd.read_csv(path)\n",
    "    df = pd.merge(df, refs, how=\"inner\", on=\"prod_id\")\n",
    "    df[\"summary\"] = df[\"summary\"].replace(np.nan, \"\")\n",
    "    all_scores = []\n",
    "    all_scores_with_prod_id = dict()\n",
    "    for i,prod_id in enumerate(df[\"prod_id\"].unique()):\n",
    "        data = df.loc[df[\"prod_id\"] == prod_id]\n",
    "        gen_summ = data[\"summary\"].values[0]\n",
    "        ref_summ = [data[\"summ_1\"].values[0], data[\"summ_2\"].values[0], data[\"summ_3\"].values[0]]\n",
    "        prod_scores = []\n",
    "        for rs in ref_summ:\n",
    "            #ref = ' '.join([str(word) for word in self.nlp(str(ref)) if str(word) not inself.stopwords])\n",
    "            rs = \" \".join(tokenize(rs))\n",
    "            gen_summ_ = \" \".join(tokenize(gen_summ))\n",
    "            scores = scorer.score(gen_summ_, rs)\n",
    "            r1_p, r1_r, r1_f = scores[\"rouge1\"]\n",
    "            r2_p, r2_r, r2_f = scores[\"rouge2\"]\n",
    "            rL_p, rL_r, rL_f = scores[\"rougeL\"]\n",
    "            prod_scores.append([[r1_p, r1_r, r1_f], [r2_p, r2_r, r2_f], [rL_p, rL_r, rL_f]])\n",
    "        \n",
    "        prod_score_arr = np.array(prod_scores)\n",
    "        all_scores.append(prod_scores)\n",
    "        all_scores_with_prod_id[prod_id] = {\n",
    "            \"rouge1\": {\n",
    "                \"precision\": {\"mean\": round(prod_score_arr.mean(0)[0][0], 5), \"max\": round(prod_score_arr.max(0)[0][0], 5), \"min\": round(prod_score_arr.min(0)[0][0], 5)},\n",
    "                \"recall\": {\"mean\": round(prod_score_arr.mean(0)[0][1], 5), \"max\": round(prod_score_arr.max(0)[0][1], 5), \"min\": round(prod_score_arr.min(0)[0][1], 5)},\n",
    "                \"fscore\": {\"mean\": round(prod_score_arr.mean(0)[0][1], 5), \"max\": round(prod_score_arr.max(0)[0][2], 5), \"min\": round(prod_score_arr.min(0)[0][2], 5)}\n",
    "            },\n",
    "            \"rouge2\": {\n",
    "                \"precision\": {\"mean\": round(prod_score_arr.mean(0)[1][0], 5), \"max\": round(prod_score_arr.max(0)[1][0], 5), \"min\": round(prod_score_arr.min(0)[1][0], 5)},\n",
    "                \"recall\": {\"mean\": round(prod_score_arr.mean(0)[1][1], 5), \"max\": round(prod_score_arr.max(0)[1][1], 5), \"min\": round(prod_score_arr.min(0)[1][1], 5)},\n",
    "                \"fscore\": {\"mean\": round(prod_score_arr.mean(0)[1][2], 5), \"max\": round(prod_score_arr.max(0)[1][2], 5), \"min\": round(prod_score_arr.min(0)[1][2], 5)}\n",
    "            },\n",
    "            \"rougeL\": {\n",
    "                \"precision\": {\"mean\": round(prod_score_arr.mean(0)[2][0], 5), \"max\": round(prod_score_arr.max(0)[2][0], 5), \"min\": round(prod_score_arr.min(0)[2][0], 5)},\n",
    "                \"recall\": {\"mean\": round(prod_score_arr.mean(0)[2][1], 5), \"max\": round(prod_score_arr.max(0)[2][1], 5), \"min\": round(prod_score_arr.min(0)[2][1], 5)},\n",
    "                \"fscore\": {\"mean\": round(prod_score_arr.mean(0)[2][2], 5), \"max\": round(prod_score_arr.max(0)[2][2], 5), \"min\": round(prod_score_arr.min(0)[2][2], 5)}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        #if prod_id == \"B0096HVJGM\":\n",
    "        print(\"===========\", prod_id)\n",
    "        print(gen_summ)\n",
    "        print()\n",
    "        for r in  ref_summ:\n",
    "            print(\">>   \", r)\n",
    "        print()\n",
    "        print()\n",
    "        print(all_scores_with_prod_id[prod_id])\n",
    "        print(\"-\"*100)\n",
    "        if i == 3:\n",
    "            pause\n",
    "        \n",
    "    all_scores = np.array(all_scores)\n",
    "    mean_scores = all_scores.mean(1).mean(0)\n",
    "    max_scores = all_scores.max(1).mean(0)\n",
    "    min_scores = all_scores.min(1).mean(0)\n",
    "    \n",
    "    output = {\n",
    "        \"rouge1\": {\n",
    "            \"precision\": {\"mean\": round(mean_scores[0][0], 5), \"max\": round(max_scores[0][0], 5), \"min\": round(min_scores[0][0], 5)},\n",
    "            \"recall\": {\"mean\": round(mean_scores[0][1], 5), \"max\": round(max_scores[0][1], 5), \"min\": round(min_scores[0][1], 5)},\n",
    "            \"fscore\": {\"mean\": round(mean_scores[0][2], 5), \"max\": round(max_scores[0][2], 5), \"min\": round(min_scores[0][2], 5)}\n",
    "        },\n",
    "        \"rouge2\": {\n",
    "            \"precision\": {\"mean\": round(mean_scores[1][0], 5), \"max\": round(max_scores[1][0], 5), \"min\": round(min_scores[1][0], 5)},\n",
    "            \"recall\": {\"mean\": round(mean_scores[1][1], 5), \"max\": round(max_scores[1][1], 5), \"min\": round(min_scores[1][1], 5)},\n",
    "            \"fscore\": {\"mean\": round(mean_scores[1][2], 5), \"max\": round(max_scores[1][2], 5), \"min\": round(min_scores[1][2], 5)}\n",
    "        },\n",
    "        \"rougeL\": {\n",
    "            \"precision\": {\"mean\": round(mean_scores[2][0], 5), \"max\": round(max_scores[2][0], 5), \"min\": round(min_scores[2][0], 5)},\n",
    "            \"recall\": {\"mean\": round(mean_scores[2][1], 5), \"max\": round(max_scores[2][1], 5), \"min\": round(min_scores[2][1], 5)},\n",
    "            \"fscore\": {\"mean\": round(mean_scores[2][2], 5), \"max\": round(max_scores[2][2], 5), \"min\": round(min_scores[2][2], 5)}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return output, all_scores_with_prod_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68186b3-b4d0-4264-a68b-2c928fc4c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_csv(model, scores):\n",
    "    df = []\n",
    "    for prod_id in scores.keys():\n",
    "        data = scores[prod_id]\n",
    "        row = dict()\n",
    "        row[\"model\"] = model\n",
    "        row[\"prod_id\"] = prod_id\n",
    "        for k,v in zip([\"r1\", \"r2\", \"rL\"], [\"rouge1\", \"rouge2\", \"rougeL\"]):\n",
    "            for m in [\"precision\", \"recall\", \"fscore\"]:\n",
    "                row[f\"{k}_{m}_mean\"] = data[v][m][\"mean\"]\n",
    "                row[f\"{k}_{m}_max\"] = data[v][m][\"max\"]\n",
    "                row[f\"{k}_{m}_min\"] = data[v][m][\"min\"]\n",
    "        df.append(row)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e534339-9d98-4c9a-9d28-aa2e3260c783",
   "metadata": {},
   "source": [
    "### Save ROUGE scores in Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5debcd53-5f90-4cad-a713-912279230cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_scores, gpt2_all_scores_with_prod_id = get_scores(path=\"gpt2_summaries.csv\", refs=refs)\n",
    "with open('gpt2_avg_scores.json', 'w') as f:\n",
    "    json.dump(gpt2_scores, f)\n",
    "\n",
    "with open('gpt2_all_scores.json', 'w') as f:\n",
    "    json.dump(gpt2_all_scores_with_prod_id, f)\n",
    "    \n",
    "gpt2_scores_csv = metrics_csv(\"gpt2\", gpt2_all_scores_with_prod_id)\n",
    "gpt2_scores_csv.to_csv(\"gpt2_all_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c0f9ff2-9456-4e9f-b2df-700ae6cde64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_scores, tr_all_scores_with_prod_id = get_scores(path=\"textrank_summaries.csv\", refs=refs)\n",
    "with open('textrank_avg_scores.json', 'w') as f:\n",
    "    json.dump(textrank_scores, f)\n",
    "    \n",
    "with open('textrank_all_scores.json', 'w') as f:\n",
    "    json.dump(tr_all_scores_with_prod_id, f)\n",
    "    \n",
    "tr_scores_csv = metrics_csv(\"textrank\", tr_all_scores_with_prod_id)\n",
    "tr_scores_csv.to_csv(\"textrank_all_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "132d38a6-dc03-46b6-8a79-a8617d0aafa5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'meansum_summaries.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m meansum_scores, meansum_all_scores_with_prod_id \u001b[38;5;241m=\u001b[39m \u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeansum_summaries.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeansum_avg_scores.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(meansum_scores, f)\n",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36mget_scores\u001b[1;34m(path, refs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_scores\u001b[39m(path, refs):\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, refs, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl-env\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'meansum_summaries.csv'"
     ]
    }
   ],
   "source": [
    "meansum_scores, meansum_all_scores_with_prod_id = get_scores(path=\"meansum_summaries.csv\", refs=refs)\n",
    "with open('meansum_avg_scores.json', 'w') as f:\n",
    "    json.dump(meansum_scores, f)\n",
    "    \n",
    "with open('meansum_all_scores.json', 'w') as f:\n",
    "    json.dump(meansum_all_scores_with_prod_id, f)\n",
    "    \n",
    "meansum_scores_csv = metrics_csv(\"meansum\", meansum_all_scores_with_prod_id)\n",
    "meansum_scores_csv.to_csv(\"meansum_all_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3ee73d1-9739-4ffb-b2d2-69fcf6680bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== B000JCDUFG\n",
      "Thanks Denver Post. Not once, but twice in two weeks. I give the Denver Post 3 stars because there is no Weather (really? Reading it is so easy....love saving the trees! So easy to hold.\n",
      "\n",
      ">>    the customers feel that the newspaper they bougth is worth reading and got information regarding the local activities and prices are reasonale too.\n",
      ">>    the newspaper is a nice read with updated news everyday. however it doesn't always arrive on time, and it has some delivery problems.\n",
      ">>    the newspaper is easy to read and navigate and apart from some delivery issues is well made\n",
      "\n",
      "\n",
      "{'rouge1': {'precision': {'mean': 0.06268, 'max': 0.11111, 'min': 0.0}, 'recall': {'mean': 0.03704, 'max': 0.05556, 'min': 0.0}, 'fscore': {'mean': 0.03704, 'max': 0.07407, 'min': 0.0}}, 'rouge2': {'precision': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'recall': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'fscore': {'mean': 0.0, 'max': 0.0, 'min': 0.0}}, 'rougeL': {'precision': {'mean': 0.06268, 'max': 0.11111, 'min': 0.0}, 'recall': {'mean': 0.03704, 'max': 0.05556, 'min': 0.0}, 'fscore': {'mean': 0.0462, 'max': 0.07407, 'min': 0.0}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "=========== B000M92GLK\n",
      "I can't believe I was able to buy it for such a low price! Very good clarity, so much so that you have to turn the volume down. This headset delivers everything as advertised by Plantronics. I purchased this model because it is compatible with the iPhone. In fact I actually had to turn down the volume a bit. Overall a very clean design. The DC charging station/dock for the car is great. Call volume was low and the amount of static\n",
      "was unbearable. I really expected more from Plantronics.\n",
      "\n",
      ">>    a headset that is light and comfortable with a good fit and good quality and very loud sound, for a lower price.\n",
      ">>    this bluetooth handsfree works great, has very good clarity and noise cancellation, is easy to use, requires no configuration, charges through pc usb port, and the sound is sharp, clear, and crisp.it is sometimes not recognized by the system for use.\n",
      ">>    the headset is well made and it's really easy to connect to bluetooth. the microphone has a nice quality and the sound is good. however it has mechanical problems, and the material quality isn't the highest.\n",
      "\n",
      "\n",
      "{'rouge1': {'precision': {'mean': 0.18994, 'max': 0.27273, 'min': 0.13043}, 'recall': {'mean': 0.07143, 'max': 0.07143, 'min': 0.07143}, 'fscore': {'mean': 0.07143, 'max': 0.11321, 'min': 0.09231}}, 'rouge2': {'precision': {'mean': 0.01515, 'max': 0.04545, 'min': 0.0}, 'recall': {'mean': 0.00813, 'max': 0.02439, 'min': 0.0}, 'fscore': {'mean': 0.01058, 'max': 0.03175, 'min': 0.0}}, 'rougeL': {'precision': {'mean': 0.09633, 'max': 0.11111, 'min': 0.08696}, 'recall': {'mean': 0.03968, 'max': 0.04762, 'min': 0.02381}, 'fscore': {'mean': 0.05531, 'max': 0.06667, 'min': 0.03774}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "=========== B000Q5J2M6\n",
      "Well, it's not working the way it's intended. This is the first bluetooth device I have tried to own. Those are my issues with it. Amazaon quickly replaced it and the second unit works well. Even comes with a carrying case! they just came apart at the seam. My 700 LX arrived and would not take a charge.\n",
      "\n",
      ">>    Overall the reviews are mixed, while some users note the superb audio quality and other users are disappointed and received a defective unit.\n",
      ">>    A lightweight Bluetooth headset. Compatible with many devices, including iPhone. Automatic answer feature. Loud incoming call volume.\n",
      ">>    the headset offers good volume control for incoming sounds, but it sometimes has a problem holding a charge.\n",
      "\n",
      "\n",
      "{'rouge1': {'precision': {'mean': 0.05808, 'max': 0.09091, 'min': 0.0}, 'recall': {'mean': 0.02564, 'max': 0.03846, 'min': 0.0}, 'fscore': {'mean': 0.02564, 'max': 0.05405, 'min': 0.0}}, 'rouge2': {'precision': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'recall': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'fscore': {'mean': 0.0, 'max': 0.0, 'min': 0.0}}, 'rougeL': {'precision': {'mean': 0.05808, 'max': 0.09091, 'min': 0.0}, 'recall': {'mean': 0.02564, 'max': 0.03846, 'min': 0.0}, 'fscore': {'mean': 0.03556, 'max': 0.05405, 'min': 0.0}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "=========== B000SRGF2W\n",
      "The characters just seemed too vague. This was a fun read, but don't expect anything other than that. It is extremely smutty and the use of fowl language is horrible. This was the case in this novel. Not too realistic. But if you are looking for an easy beach read, this one is for you!\n",
      "\n",
      ">>    This short military romance story, Male Call, was predictable but enjoyable. The letters the characters write to each other helped move the story along.\n",
      ">>    short story with a lot of sex. seems a bit immature. needs more to the story about when he comes back home.\n",
      ">>    the book brings fun to readers, at a good price, but the plot is short and deals with a lot of sexual content.\n",
      "\n",
      "\n",
      "{'rouge1': {'precision': {'mean': 0.05159, 'max': 0.08333, 'min': 0.0}, 'recall': {'mean': 0.03333, 'max': 0.05, 'min': 0.0}, 'fscore': {'mean': 0.03333, 'max': 0.0625, 'min': 0.0}}, 'rouge2': {'precision': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'recall': {'mean': 0.0, 'max': 0.0, 'min': 0.0}, 'fscore': {'mean': 0.0, 'max': 0.0, 'min': 0.0}}, 'rougeL': {'precision': {'mean': 0.05159, 'max': 0.08333, 'min': 0.0}, 'recall': {'mean': 0.03333, 'max': 0.05, 'min': 0.0}, 'fscore': {'mean': 0.04044, 'max': 0.0625, 'min': 0.0}}}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neutralsumm_scores, neutralsumm_all_scores_with_prod_id \u001b[38;5;241m=\u001b[39m \u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../outputs/gpt2_summaries.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m neutralsumm_scores\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mget_scores\u001b[1;34m(path, refs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m---> 53\u001b[0m         \u001b[43mpause\u001b[49m\n\u001b[0;32m     55\u001b[0m all_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_scores)\n\u001b[0;32m     56\u001b[0m mean_scores \u001b[38;5;241m=\u001b[39m all_scores\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pause' is not defined"
     ]
    }
   ],
   "source": [
    "neutralsumm_scores, neutralsumm_all_scores_with_prod_id = get_scores(path=\"../outputs/gpt2_summaries.csv\", refs=refs)\n",
    "neutralsumm_scores\n",
    "#with open('neutralsumm_avg_scores.json', 'w') as f:\n",
    "#    json.dump(neutralsumm_scores, f)\n",
    "    \n",
    "#with open('neutralsumm_all_scores.json', 'w') as f:\n",
    "#    json.dump(neutralsumm_all_scores_with_prod_id, f)\n",
    "    \n",
    "#neutralsumm_scores_csv = metrics_csv(\"neutralsumm\", neutralsumm_all_scores_with_prod_id)\n",
    "#neutralsumm_scores_csv.to_csv(\"neutralsumm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5569a93-a0f9-42f7-b146-fdc874ba786f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
